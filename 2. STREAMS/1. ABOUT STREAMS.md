# WHAT DO I KNOW ABOUT STREAMS

LETS SAY YOU HAVE GOOD "DATA ENTITY"

LETS SAY YOU HAVE TO DO BUNCH OF THING ON THAT "DATA ENTITY"

LETS SAY YOU NEED TO COMPRESS IT, DO SOME TRANSFOMATIONS ON IT, DO SOMETHING ELSE, THEN FILTER SOMETHING OUT, ADD SOMETHING IN

TRADITIONALLY YOU WOULD DO THIS THINGS IN A WAY THAT YOU WOULD INITIATE SOME PROCESS, AND WHEN THAT PROCESS ENDS ANOTHER PROCESS WOULD START, NTILL EVERY PROCESS ONE AFTER ANOTHER IS FINISED

**WITH STREAM YOU CAN DEFINE THAT "ENTITY OF DATA" IS CHUNKED AND YOU RUN ALL PROCESSES, CHUNK by CHUNK**

IT'S LIKE YOU SPLIT THING ON PIECES AND YOU DO ONE THING ON ONE PIECE AND YOU DO IT WELL

THIS IS GOOD WHEN YOU NEED TO PIPE ONE THING TO ANOTHER

**SO WITH STREAMS WE CA `COMPOSE STREAMING ABSTRACTIONS` AND WE CAN `OPERATE ON DATA CHUNK BY CHUNK`**

## OK, IMAGINE YOU HAVE SERVER WHERE YOU NEED TO STREAM OUT 100Mb VIDEO FILES

IT WOULD BE BAD IF YOU WOULD READ ENTIRE FILE AND THEN WRITE IT OUT

AND LETS SAY YOU HAVE 1000000 FILES ON YOUR SERVER AND THAT WOULD BE EXPENSIVE; **YOUR MAMORY WOULD SUFFER SO MUCH**; **INSTEAD OF THAT, IT WOULD BE BETTER TO KEEP JUST A CHUNK OF FILE IN MEMORY, AND WHEN CHUNK GETS PROCESSED, HIS PLACE TAKES ANOTHER CHUNK**

TO BE MORE SIMPLE:

SO YOU LET USER TO DOWNLOAD CHUNK AND TO PLAY OUT THAT CHUNK, AND WHEN ONE CHUNK IS DOWNLOAD ANOTHER CHUNK STARTS DOWNLOADING

THAT WOULD BE BETTER OF COURS

# STREAMS HAVE `pipe` METHOD WHICH IS OFTTEN USED

SEE THIS PSEUDO CODE

```js
// WE ARE READING SOME DATA CHUNK BY CHUNK
fs.createReadStream(SOMETHING)
.pipe(DoDomethingElseOnA_CHUNK())
.pipe(DoDomethingElseOnA_CHUNK())
.pipe(DoDomethingElseOnA_CHUNK())
.pipe(DoDomethingElseOnA_CHUNK())
.pipe(DoDomethingElseOnA_CHUNK())

// CHUNK BY CHUNK
// EACH CHUNK GOES IN ORDER, ONE STEP AFTER ANOTHER STEP IS 
// OPERATED ON THAT ONE CHUNK, TILL ALL STEPS ARE FINISHED
// AFTER ONE CHUNK IS FINISHED WITH OPERATED ON, NEW CHUNK WILL BE
// OPERATED ON
```

# LETS LEARN ABOUT `process.stdin`, `process.stdout`, `process.argv`

file.js

```js
// before we start here are some facts
// process.argv HOLDS ARRAY WITH SOME DATA
// HERE IS HOW IT LOOKS

/*      

  [
    "path to where node is installed on your system",
    "path of the file who is runned against "node" executable"
    // EVERY NEXT ARGUMENT IS ANYTHING THAT IS PASSED WHEN YOU RUNNED

    // node      IF YOU RUNNED      node file.js foo bar
    // NEXT ARRAY ITEMs WOULD BE   "foo", "bar"


  ]

*/
console.log(process.argv)

// WE HAVE STANDARD OUTPUT AND STANDARD INPUT

// THIS IS READABLE STREAM (ALI OVO JE CIRCULAR REFERENCE)
// THIS LISTNES FOR THE USERS INPUT; EVERYTHING THAT IS PASSED IN
// WITH EXECUTABLE
// console.log(process.stdin)

// WE CAN LISTEN USER DATA IN HERE
// BECAUSE YOU USE THIS YOU WILL BE PROMPTED TO WRITE SOMETHING
// IN TERMINAL
// WHEN YOU WRITE AND PRESS ENTER, PROCESS WILL EXIT
process.stdin.on("data", (data) => {
  // 

  console.log({data: data.toString("utf8")})
  process.exit()
  // 
})


// THIS IS WRITABLE STREAM (ALI OVO JE CIRCULAR REFERENCE)
// console.log(process.stdout)
// 
```

# `ReadStream`.`pipe`

> The readable.pipe() method attaches a Writable stream to the readable, causing it to switch automatically into flowing mode and push all of its data to the attached Writable. The flow of data will be automatically managed so that the destination Writable stream is not overwhelmed by a faster Readable stream.

EXAMPLE

```js
const {createReadStream} = require("fs")

createReadStream(process.argv[1]).pipe(process.stdout)

```

RUN FILE AGAINST NODE EXECUTABLE AND THAT SHOULD PRINT THE CONTENT OF FILE


CHECK THIS OUT

