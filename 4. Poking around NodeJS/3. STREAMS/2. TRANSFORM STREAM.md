# TRANSFORM STREAM

LAST TIME WE WERE USING THINGS LIKE `"through2"`, `"conct-stream"`, `"split2"`

WE ALSO TRIED `Transform` CONSTRUCTOR FROM NATIVE PACKAGE `"stream"`

LETS SEE EXAMPLE

```
code _exercise_2/foobar.js
```

```js
#!/usr/bin/env node
"use strict"

const {createReadStream} = require("fs")
const path = require("path")

// WE ARE USING THIS PACKAGE
const {Transform} = require("stream")

const minimist = require("minimist");


// LETS CREATE TRNSFORMATION
const transToUpperCase = new Transform({

  // REMEBER THAT IF YOU DEFINE THIS AS AN ARROW FUNC
  // YOU CAN'T USE      this
  transform: (chunkBuff, chunkEnc, next) => {
    
    

    // I LIKE DOING THINGS LIKE THIS
    next(null, chunkBuff.toString().toUpperCase())

    // SOME PEOPLE ARE USING        this.push
    // LIKE THIS

    //      this.push(chunkBuff.toString().toUpperCase())
    //      next()

  }
})


const args = minimist(process.argv.slice(2), {
  boolean: ["help"],
  string: ["file"]
})


if(args["help"]){
  return printHelp()
}

if(!args["file"]){
  return printError("You must provide file path", true)
}


const filePath = path.resolve(args["file"])


const neuReadStream = createReadStream(filePath)

neuReadStream.on("error", (err) => {

  printError(err.message)
})

neuReadStream.pipe(transToUpperCase).pipe(process.stdout);

// *****************************************

function printHelp(){
  console.log(`
          foobar --help

  --help          getting help
  --file          specify file path (string)
  `)
}

function printError(msg, includeHelp = false){

  console.error(msg)

  if(includeHelp){
    printHelp()
  }
}
```

RUN IT

```
_exercise_2/foobar.js --file _exercise/someFile1.txt

```

## I WANT TO ALTER EXAMPLE A BIT IN ORDER TO EXPLICITLY SHOW YOU THAT THERE ARE MANY BUFFERS "FLOWING" IN BETWEEN READABLE AND WRITIBLE WHEN YOU'RE PIPING

I ASUME THAT IN NODEJS THERE IS DEFAULT SETTED OF HOW BIG A BUFFER SHOULD BE WHEN PIPING HAPPENS, AND ACORDING TO THAT IT IS DETERMINED HOW BIG CN BE THE "FLOWING" CHUNKS

LETS ALTER THE EXAMPLE

```
code _exercise_2/foobar.js
```

```js
#!/usr/bin/env node
"use strict"

const {createReadStream} = require("fs")
const path = require("path")

const {Transform} = require("stream")

const minimist = require("minimist");

// LETS USE COUNTER
let num = 0;

const transToUpperCase = new Transform({

  // THIS WAY THIS CAN BE AN ARROW FUNCTION
  transform: (chunkBuff, chunkEnc, next) => {
    
    // OK, LETS PRINT OUT THE CHUNK
    console.log({chunkBuff})
    // INCREMENTING
    num++;
    // INSTEAD OF PASSING TRANSFORMED DATA
    // next(null, chunkBuff.toString().toUpperCase())
    // LETS PASS INCREMENT, BUT YOU NEED TO TURN IT TO STRING
    next(null, num + "\n")

  }
})


const args = minimist(process.argv.slice(2), {
  boolean: ["help"],
  string: ["file"]
})


if(args["help"]){
  return printHelp()
}

if(!args["file"]){
  return printError("You must provide file path", true)
}


const filePath = path.resolve(args["file"])


const neuReadStream = createReadStream(filePath)

neuReadStream.on("error", (err) => {

  printError(err.message)
})

neuReadStream.pipe(transToUpperCase).pipe(process.stdout);

// *****************************************

function printHelp(){
  console.log(`
          foobar --help

  --help          getting help
  --file          specify file path (string)
  `)
}

function printError(msg, includeHelp = false){

  console.error(msg)

  if(includeHelp){
    printHelp()
  }
}
```

**WE ARE GOING TO READ FROM A VERY LARGE FILE**

```
_exercise_2/foobar.js --file _exercise_2/blog-post.mdx
```

AND THIS IS WHAT'S GET OUTPUTED

```
{
  chunkBuff: <Buffer 49 20 6d 61 64 65 20 61 20 67 72 6f 75 70 20 6f 66 20 70 6f 73 74 73 20 61 6e 64 20 6f 74 68 65 72 20 72 65 73 6f 75 72 63 65 73 2c 20 63 6f 6d 62 69 ... 65486 more bytes>
}
1
{
  chunkBuff: <Buffer 2f 64 65 76 65 6c 6f 70 65 72 2e 6d 6f 7a 69 6c 6c 61 2e 6f 72 67 2f 65 6e 2d 55 53 2f 64 6f 63 73 2f 47 6c 6f 73 73 61 72 79 2f 56 65 6e 64 6f 72 5f ... 22761 more bytes>
}
2

```

**AS YOU CAN SEE, DUTRING STREAMING, OUR DATA WAS "FLOWING" IN TWO CHUNKS; CHUNK AFTER CHUNK**

**ALSO, WE ALREADY KNOW BOUT AND WE HAVE USED PACKAGE `"split2"` WHICH ALLOWS US TO SPLIT DATA EVEN IN MORE CHUNKS**